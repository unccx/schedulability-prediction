{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../DeepHypergraph/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dhg import Hypergraph\n",
    "from dhg.data import DBLP8k\n",
    "from dhg.models import HGNNPLinkPred\n",
    "from dhg.random import set_seed\n",
    "from dhg.metrics import LinkPredictionEvaluator as Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, X, hypergraph, negative_hypergraph, optimizer, epoch):\n",
    "    net.train()\n",
    "\n",
    "    st = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    pos_score = net(X, hypergraph)\n",
    "    neg_score = net(X, negative_hypergraph)\n",
    "\n",
    "    global device\n",
    "    scores = torch.cat([pos_score, neg_score]).squeeze()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).to(device)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Time: {time.time()-st:.5f}s, Loss: {loss.item():.5f}\")\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(net, X, hypergraph, negative_hypergraph, test=False):\n",
    "    net.eval()\n",
    "    pos_score = net(X, hypergraph)\n",
    "    neg_score = net(X, negative_hypergraph)\n",
    "\n",
    "    scores = torch.cat([pos_score, neg_score]).squeeze()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).to(device)\n",
    "\n",
    "    global evaluator\n",
    "    if not test:\n",
    "        res = evaluator.validate(labels, scores)\n",
    "    else:\n",
    "        res = evaluator.test(labels, scores)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data(file_path: Path):\n",
    "    hyperedge_list = []\n",
    "    neg_hyperedge_list = []\n",
    "    with open(file_path / \"hyperedges.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # 读取每个超边的顶点列表，并将它们添加到 hyperedge_list 中\n",
    "            hyperedge_list.append(row)\n",
    "    \n",
    "    hyperedge_list = [[int(v) for v in edge] for edge in hyperedge_list]\n",
    "\n",
    "    with open(file_path / \"minimal_unschedulable_combinations.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            neg_hyperedge_list.append(row) \n",
    "\n",
    "    neg_hyperedge_list = [[int(v) for v in edge] for edge in neg_hyperedge_list]\n",
    "\n",
    "    with open(file_path / \"task_quadruples.csv\", 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = [list(map(float, row)) for row in reader]\n",
    "\n",
    "    # 将数据转换为 Tensor\n",
    "    features = torch.tensor(data)\n",
    "\n",
    "    data = {\"hyperedge_list\": hyperedge_list, \"num_edges\" : len(hyperedge_list)}\n",
    "    neg_data = {\"hyperedge_list\": neg_hyperedge_list, \"num_edges\" : len(neg_hyperedge_list)}\n",
    "\n",
    "    return {\"pos\":data, \"neg\": neg_data, \"vertices_feature\" : features, \"num_vertices\" : features.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(2021)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "evaluator = Evaluator([\"accuracy\", \"auc\", \"f1_score\"])\n",
    "train_data =    load_data(Path(\"../EDF/data/data_s3000_p3_t1000_hs7_e10000/\"))\n",
    "validate_data = load_data(Path(\"../EDF/data/data_s3001_p3_t1000_hs7_e10000/\"))\n",
    "test_data =     load_data(Path(\"../EDF/data/data_s3002_p3_t1000_hs7_e10000/\"))\n",
    "\n",
    "X = train_data[\"vertices_feature\"]\n",
    "HG = Hypergraph(train_data[\"num_vertices\"], train_data[\"pos\"][\"hyperedge_list\"])\n",
    "neg_HG = Hypergraph(train_data[\"num_vertices\"], train_data[\"neg\"][\"hyperedge_list\"])\n",
    "\n",
    "validate_X = validate_data[\"vertices_feature\"]\n",
    "validate_HG = Hypergraph(validate_data[\"num_vertices\"], validate_data[\"pos\"][\"hyperedge_list\"])\n",
    "validate_neg_HG = Hypergraph(validate_data[\"num_vertices\"], validate_data[\"neg\"][\"hyperedge_list\"])\n",
    "\n",
    "test_X = test_data[\"vertices_feature\"]\n",
    "test_HG = Hypergraph(test_data[\"num_vertices\"], test_data[\"pos\"][\"hyperedge_list\"])\n",
    "test_neg_HG = Hypergraph(test_data[\"num_vertices\"], test_data[\"neg\"][\"hyperedge_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_sparsity(matrix):\n",
    "    nonzero_elements = np.count_nonzero(matrix)\n",
    "    total_elements = matrix.size\n",
    "\n",
    "    nonzero_ratio = nonzero_elements / total_elements\n",
    "    zero_ratio = 1 - nonzero_ratio\n",
    "\n",
    "    print(f\"非零元素比例：{nonzero_ratio:.2%}\")\n",
    "    print(f\"零元素比例：{zero_ratio:.2%}\")\n",
    "\n",
    "calculate_sparsity(HG.H.to_dense().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_values = HG.deg_v\n",
    "# degree_values = validate_HG.deg_v\n",
    "# degree_values = test_HG.deg_v\n",
    "print(degree_values)\n",
    "print(degree_values[489])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 绘制节点度数的柱状图\n",
    "plt.bar(range(len(degree_values)), degree_values)\n",
    "plt.xticks(range(len(degree_values)), range(len(degree_values)))\n",
    "plt.xlabel('Node Index')\n",
    "plt.ylabel('Degree')\n",
    "plt.title('Degree Distribution')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DHG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
