{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/arc/Development/DeepHypergraph/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dhg import Hypergraph\n",
    "from dhg.data import DBLP8k\n",
    "from dhg.models import HGNNPLinkPred\n",
    "from dhg.random import set_seed\n",
    "from dhg.metrics import LinkPredictionEvaluator as Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, X, hypergraph, negative_hypergraph, optimizer, epoch):\n",
    "    net.train()\n",
    "\n",
    "    st = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    pos_score = net(X, hypergraph)\n",
    "    neg_score = net(X, negative_hypergraph)\n",
    "\n",
    "    scores = torch.cat([pos_score, neg_score]).squeeze()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).to(device)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, Time: {time.time()-st:.5f}s, Loss: {loss.item():.5f}\")\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(net, X, hypergraph, negative_hypergraph, test=False):\n",
    "    net.eval()\n",
    "    pos_score = net(X, hypergraph)\n",
    "    neg_score = net(X, negative_hypergraph)\n",
    "\n",
    "    scores = torch.cat([pos_score, neg_score]).squeeze()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).to(device)\n",
    "\n",
    "    if not test:\n",
    "        res = evaluator.validate(labels, scores)\n",
    "    else:\n",
    "        res = evaluator.test(labels, scores)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data(file_path: Path):\n",
    "    hyperedge_list = []\n",
    "    neg_hyperedge_list = []\n",
    "    with open(file_path / \"hyperedges.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # 读取每个超边的顶点列表，并将它们添加到 hyperedge_list 中\n",
    "            hyperedge_list.append(row)\n",
    "    \n",
    "    hyperedge_list = [[int(v) for v in edge] for edge in hyperedge_list]\n",
    "\n",
    "    with open(file_path / \"minimal_unschedulable_combinations.csv\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            neg_hyperedge_list.append(row) \n",
    "\n",
    "    neg_hyperedge_list = [[int(v) for v in edge] for edge in neg_hyperedge_list]\n",
    "\n",
    "    with open(file_path / \"task_quadruples.csv\", 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = [list(map(float, row)) for row in reader]\n",
    "\n",
    "    # 将数据转换为 Tensor\n",
    "    features = torch.tensor(data)\n",
    "\n",
    "    data = {\"hyperedge_list\": hyperedge_list, \"num_edges\" : len(hyperedge_list)}\n",
    "    neg_data = {\"hyperedge_list\": neg_hyperedge_list, \"num_edges\" : len(neg_hyperedge_list)}\n",
    "\n",
    "    return {\"pos\":data, \"neg\": neg_data, \"vertices_feature\" : features, \"num_vertices\" : features.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(2021)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "evaluator = Evaluator([\"accuracy\", \"auc\"])\n",
    "train_data = load_data(Path(\"../EDF/data/data_s2233_p10_t21/\"))\n",
    "test_data = load_data(Path(\"../EDF/data/data_s2234_p10_t21/\"))\n",
    "\n",
    "X = train_data[\"vertices_feature\"]\n",
    "HG = Hypergraph(train_data[\"num_vertices\"], train_data[\"pos\"][\"hyperedge_list\"])\n",
    "neg_HG = Hypergraph(train_data[\"num_vertices\"], train_data[\"neg\"][\"hyperedge_list\"])\n",
    "\n",
    "test_X = test_data[\"vertices_feature\"]\n",
    "test_HG = Hypergraph(test_data[\"num_vertices\"], test_data[\"pos\"][\"hyperedge_list\"])\n",
    "test_neg_HG = Hypergraph(test_data[\"num_vertices\"], test_data[\"neg\"][\"hyperedge_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_sparsity(matrix):\n",
    "    nonzero_elements = np.count_nonzero(matrix)\n",
    "    total_elements = matrix.size\n",
    "\n",
    "    nonzero_ratio = nonzero_elements / total_elements\n",
    "    zero_ratio = 1 - nonzero_ratio\n",
    "\n",
    "    print(f\"非零元素比例：{nonzero_ratio:.2%}\")\n",
    "    print(f\"零元素比例：{zero_ratio:.2%}\")\n",
    "\n",
    "# calculate_sparsity(HG.H.to_dense().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HGNNPLinkPred(X.shape[1], 64, 32, use_bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.0001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to(device)\n",
    "HG = HG.to(device)\n",
    "neg_HG = neg_HG.to(device)\n",
    "net = net.to(device)\n",
    "\n",
    "test_X = test_X.to(device)\n",
    "test_HG = test_HG.to(device)\n",
    "test_neg_HG = test_neg_HG.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X: {X.device}\")\n",
    "print(f\"HG: {HG.device}\")\n",
    "print(f\"neg_HG: {neg_HG.device}\")\n",
    "print(f\"net: {next(net.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_state = None\n",
    "best_epoch, best_val = 0, 0\n",
    "for epoch in range(200):\n",
    "    # train\n",
    "    train(net, X, HG, neg_HG, optimizer, epoch)\n",
    "    # validation\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            val_res = infer(net, test_X, test_HG, test_neg_HG)\n",
    "        if val_res > best_val:\n",
    "            print(f\"update best: {val_res:.5f}\")\n",
    "            best_epoch = epoch\n",
    "            best_val = val_res\n",
    "            best_state = deepcopy(net.state_dict())\n",
    "print(\"\\ntrain finished!\")\n",
    "print(f\"best val: {best_val:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "print(\"test...\")\n",
    "net.load_state_dict(best_state)\n",
    "res = infer(net, test_X, test_HG, test_neg_HG, test=True)\n",
    "print(f\"final result: epoch: {best_epoch}\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DHG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
